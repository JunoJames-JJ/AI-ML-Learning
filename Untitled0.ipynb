{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVpIkiyPji9ar3CazWhcof",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JunoJames-JJ/AI-ML-Learning/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBZPrZN_6WIH",
        "outputId": "a5a1c7f6-434c-45a1-eb3a-de518de4bf75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿The Project Gutenberg eBook of Alice's Adventures in Wonderland\n",
            "    \n",
            "This ebook is for the use of anyone anywhere in the United States and\n",
            "most other parts of the world at no cost and with almost no restrictions\n",
            "whatsoever. You may copy it, give it away or re-use it under the terms\n",
            "of the Project Gutenberg License included with this ebook or online\n",
            "at www.gutenberg.org. If you are not located in the United States,\n",
            "you will have to check the laws of the country where you are located\n",
            "before using this eBook.\n",
            "\n",
            "Title: Alice's Adventures in Wonderland\n",
            "\n",
            "Author: Lewis Carroll\n",
            "\n",
            "Release date: June 27, 2008 [eBook #11]\n",
            "                Most recently updated: June 26, 2025\n",
            "\n",
            "Language: English\n",
            "\n",
            "Credits: Arthur DiBianca and David Widger\n",
            "\n",
            "\n",
            "*** START OF THE PROJECT GUTENBERG EBOOK ALICE'S ADVENTURES IN WONDERLAND ***\n",
            "\n",
            "[Illustration]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Alice’s Adventures in Wonderland\n",
            "\n",
            "by Lewis Carroll\n",
            "\n",
            "THE MILLENNIUM FULCRUM EDITION 3.0\n",
            "\n",
            "Contents\n",
            "\n",
            " CHAPTER I.     Down the Rabbit-Hole\n",
            " CHAPTER II.    The Pool of Tears\n",
            " CHAPTER III.   A Caucus-Race and a Long Tale\n",
            " CHAPTER IV.    The Rabbit Sends in a Little Bill\n",
            " CHAPTER V.     Advice from a Caterpillar\n",
            " CHAPTER VI.    Pig and Pepper\n",
            " CHAPTER VII.   A Mad Tea-Party\n",
            " CHAPTER VIII.  The Queen’s Croquet-Ground\n",
            " CHAPTER IX.    The Mock Turtle’s Story\n",
            " CHAPTER X.     The Lobster Quadrille\n",
            " CHAPTER XI.    Who Stole the Tarts?\n",
            " CHAPTER XII.   Alice’s Evidence\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "CHAPTER I.\n",
            "Down the Rabbit-Hole\n",
            "\n",
            "\n",
            "Alice was beginning to get very tired of sitting by her sister on th\n"
          ]
        }
      ],
      "source": [
        "with open(\"pg11.txt\", \"r\", encoding= \"utf-8\") as f:\n",
        "  text = f.read()\n",
        "print(text[:1500])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import gutenberg\n",
        "\n",
        "nltk.download(\"gutenberg\")\n",
        "\n",
        "print(gutenberg.fileids())\n",
        "\n",
        "alice = gutenberg.raw(\"carroll-alice.txt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJWEX4Ha-OEp",
        "outputId": "ec034914-f26e-4646-cf40-1ab1aca121c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(alice[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4D9lsbERAbLK",
        "outputId": "a4c2363f-5fbb-4304-eac5-d7b2095a0865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Alice's Adventures in Wonderland by Lewis Carroll 1865]\n",
            "\n",
            "CHAPTER I. Down the Rabbit-Hole\n",
            "\n",
            "Alice was beginning to get very tired of sitting by her sister on the\n",
            "bank, and of having nothing to do: once or twice she had peeped into the\n",
            "book her sister was reading, but it had no pictures or conversations in\n",
            "it, 'and what is the use of a book,' thought Alice 'without pictures or\n",
            "conversation?'\n",
            "\n",
            "So she was considering in her own mind (as well as she could, for the\n",
            "hot day made her feel very sleepy an\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"alice_in_wonderland.txt\", \"w\", encoding = \"utf-8\") as f:\n",
        "  f.write(alice)\n",
        "\n",
        "  print(\"Saved Alice in Wonderland to alice_in_wonderland.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-T04UcTAptO",
        "outputId": "243cb4ec-b5f1-4c10-88cd-574562160e56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Alice in Wonderland to alice_in_wonderland.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = alice[91:950]\n",
        "print(sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzLG4KI6BXQ7",
        "outputId": "5cea76d2-783f-4bc9-9391-3fdf0922b385"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alice was beginning to get very tired of sitting by her sister on the\n",
            "bank, and of having nothing to do: once or twice she had peeped into the\n",
            "book her sister was reading, but it had no pictures or conversations in\n",
            "it, 'and what is the use of a book,' thought Alice 'without pictures or\n",
            "conversation?'\n",
            "\n",
            "So she was considering in her own mind (as well as she could, for the\n",
            "hot day made her feel very sleepy and stupid), whether the pleasure\n",
            "of making a daisy-chain would be worth the trouble of getting up and\n",
            "picking the daisies, when suddenly a White Rabbit with pink eyes ran\n",
            "close by her.\n",
            "\n",
            "There was nothing so VERY remarkable in that; nor did Alice think it so\n",
            "VERY much out of the way to hear the Rabbit say to itself, 'Oh dear!\n",
            "Oh dear! I shall be late!' (when she thought it over afterwards, it\n",
            "occurred to her that she ought to have wondered at this,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "from nltk.tokenize import word_tokenize\n",
        "tokens = word_tokenize(sample)\n",
        "print(tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WK9kDH8sBkRP",
        "outputId": "fe35f50e-0790-4ae2-82e7-cd42950a85bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Alice', 'was', 'beginning', 'to', 'get', 'very', 'tired', 'of', 'sitting', 'by', 'her', 'sister', 'on', 'the', 'bank', ',', 'and', 'of', 'having', 'nothing', 'to', 'do', ':', 'once', 'or', 'twice', 'she', 'had', 'peeped', 'into', 'the', 'book', 'her', 'sister', 'was', 'reading', ',', 'but', 'it', 'had', 'no', 'pictures', 'or', 'conversations', 'in', 'it', ',', \"'and\", 'what', 'is', 'the', 'use', 'of', 'a', 'book', ',', \"'\", 'thought', 'Alice', \"'without\", 'pictures', 'or', 'conversation', '?', \"'\", 'So', 'she', 'was', 'considering', 'in', 'her', 'own', 'mind', '(', 'as', 'well', 'as', 'she', 'could', ',', 'for', 'the', 'hot', 'day', 'made', 'her', 'feel', 'very', 'sleepy', 'and', 'stupid', ')', ',', 'whether', 'the', 'pleasure', 'of', 'making', 'a', 'daisy-chain', 'would', 'be', 'worth', 'the', 'trouble', 'of', 'getting', 'up', 'and', 'picking', 'the', 'daisies', ',', 'when', 'suddenly', 'a', 'White', 'Rabbit', 'with', 'pink', 'eyes', 'ran', 'close', 'by', 'her', '.', 'There', 'was', 'nothing', 'so', 'VERY', 'remarkable', 'in', 'that', ';', 'nor', 'did', 'Alice', 'think', 'it', 'so', 'VERY', 'much', 'out', 'of', 'the', 'way', 'to', 'hear', 'the', 'Rabbit', 'say', 'to', 'itself', ',', \"'Oh\", 'dear', '!', 'Oh', 'dear', '!', 'I', 'shall', 'be', 'late', '!', \"'\", '(', 'when', 'she', 'thought', 'it', 'over', 'afterwards', ',', 'it', 'occurred', 'to', 'her', 'that', 'she', 'ought', 'to', 'have', 'wondered', 'at', 'this', ',']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "sentences = sent_tokenize(sample)\n",
        "len(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQEueVNsCJ9y",
        "outputId": "d1768403-65a0-4bd6-f662-14912c6a3d6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = sample.lower()\n",
        "print(sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2S4CZErbCdZ2",
        "outputId": "b7aebef2-c29a-4421-bca2-194ed3c9ddfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alice was beginning to get very tired of sitting by her sister on the\n",
            "bank, and of having nothing to do: once or twice she had peeped into the\n",
            "book her sister was reading, but it had no pictures or conversations in\n",
            "it, 'and what is the use of a book,' thought alice 'without pictures or\n",
            "conversation?'\n",
            "\n",
            "so she was considering in her own mind (as well as she could, for the\n",
            "hot day made her feel very sleepy and stupid), whether the pleasure\n",
            "of making a daisy-chain would be worth the trouble of getting up and\n",
            "picking the daisies, when suddenly a white rabbit with pink eyes ran\n",
            "close by her.\n",
            "\n",
            "there was nothing so very remarkable in that; nor did alice think it so\n",
            "very much out of the way to hear the rabbit say to itself, 'oh dear!\n",
            "oh dear! i shall be late!' (when she thought it over afterwards, it\n",
            "occurred to her that she ought to have wondered at this,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I live In The US and Work at NASA\"\n",
        "tokens = text.split()\n",
        "tokens = [t if t.isupper() else t.lower() for t in tokens]\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1g5620sZCrd9",
        "outputId": "b051474d-ab80-4dc9-a9ff-81d06ed7f28c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'live', 'in', 'the', 'US', 'and', 'work', 'at', 'NASA']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exceptions = {\"US\", \"NASA\"}\n",
        "tokens = text.split()\n",
        "tokens = [t if t in exceptions else t.lower() for t in tokens]\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFhgbi4fDK8j",
        "outputId": "677dbd89-c7c7-4fe9-c416-df264e107d89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'live', 'in', 'the', 'US', 'and', 'work', 'at', 'NASA']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import string\n",
        "\n",
        "print(\"punctuations: \", string.punctuation)\n",
        "print(\"\\n\")\n",
        "\n",
        "#Remove punctuation\n",
        "sample = sample.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "print(sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIQ-cjRNEwuW",
        "outputId": "a38d7a25-6f1a-4139-98b6-b3f8a856be2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "punctuations:  !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
            "\n",
            "\n",
            "alice was beginning to get very tired of sitting by her sister on the\n",
            "bank and of having nothing to do once or twice she had peeped into the\n",
            "book her sister was reading but it had no pictures or conversations in\n",
            "it and what is the use of a book thought alice without pictures or\n",
            "conversation\n",
            "\n",
            "so she was considering in her own mind as well as she could for the\n",
            "hot day made her feel very sleepy and stupid whether the pleasure\n",
            "of making a daisychain would be worth the trouble of getting up and\n",
            "picking the daisies when suddenly a white rabbit with pink eyes ran\n",
            "close by her\n",
            "\n",
            "there was nothing so very remarkable in that nor did alice think it so\n",
            "very much out of the way to hear the rabbit say to itself oh dear\n",
            "oh dear i shall be late when she thought it over afterwards it\n",
            "occurred to her that she ought to have wondered at this\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "table = str.maketrans(\"ao\", \"@o\", string.punctuation)\n",
        "\n",
        "text = \"Apples, oranges, and bananas!!!\"\n",
        "print(text.translate(table))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WOGJXhqGVKA",
        "outputId": "7e786b2a-cabd-4c85-bf50-2ba84d517411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apples or@nges @nd b@n@n@s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "table = str.maketrans(\"0123456789\", \"##########\", string.punctuation)\n",
        "text = \"Price in 2023: $500!\"\n",
        "print(text.translate(table))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jX_He6SeGu2e",
        "outputId": "5402f951-e296-498a-a5e6-f5ecfe118921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Price in #### ###\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "text = \"I am so... happy! Are you coming?\"\n",
        "keep = \"!?\"\n",
        "remove = ''.join([c for c in string.punctuation if c not in keep])\n",
        "print(\"remove list: \", remove)\n",
        "text = text.translate(str.maketrans(\"\", \"\", remove))\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dD0iq3wKHWz2",
        "outputId": "9b10f9f5-bbdf-4603-ea8b-98cd4d7df6d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remove list:  \"#$%&'()*+,-./:;<=>@[\\]^_`{|}~\n",
            "I am so happy! Are you coming?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "print(\"stop words: \", stop_words, \"\\n\")\n",
        "\n",
        "tokens = [word for word in sample.split() if word not in stop_words]\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "affa7RkYJdDs",
        "outputId": "7669331a-5398-4f5a-86fe-aec4a7902ac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stop words:  {'there', \"we'd\", 'very', 'ourselves', 'out', 'does', \"they've\", 'against', \"he'll\", 't', 'doing', \"that'll\", 'm', 'him', 'who', 'the', \"don't\", 'for', 'some', 'so', 'both', \"couldn't\", \"mightn't\", 'they', \"isn't\", 'our', 'just', 'their', 'when', 'will', 'been', 'all', 'ma', 's', 'hadn', 'them', 'couldn', 'should', 'be', 'shouldn', 'are', 'ours', 'doesn', 'through', \"it'd\", \"she's\", \"didn't\", 'wouldn', 're', 'such', 'but', 'weren', 'further', 'nor', 'themselves', 'above', \"she'll\", 'an', 'than', 'any', 'yours', 'because', 'over', 'what', 'few', 'himself', 'into', 'up', \"aren't\", 'those', 'with', 'most', 'it', 'theirs', \"we'll\", 'same', \"won't\", \"mustn't\", 'how', 'yourself', \"you'll\", 'me', 'at', 'did', \"needn't\", 'after', 'has', \"shouldn't\", 'then', \"it'll\", 'about', 'before', 'isn', 'am', 'she', \"they'd\", \"they're\", 'now', \"weren't\", 'you', 'have', \"you'd\", \"you've\", 'a', 'which', 'haven', 'll', 'mightn', 'her', \"we've\", \"you're\", 'or', 'too', 'down', 'your', 'having', \"she'd\", 'its', 'o', \"should've\", 'my', 'didn', 'herself', \"i'll\", 'we', 'he', 'that', 'y', \"wasn't\", 'whom', \"we're\", 'by', 'hers', 'his', 'if', \"they'll\", 'these', 'shan', 'was', 'mustn', 'under', 'between', 'as', \"it's\", 'own', 'aren', \"hasn't\", \"shan't\", 'don', \"haven't\", 'to', \"doesn't\", 'in', 'wasn', 'while', \"i'm\", \"he's\", 'i', 'is', 'why', 'not', 'needn', 've', 'during', 'where', 'other', 'can', 'won', 'itself', 'once', 'from', 'hasn', 'do', 'yourselves', 'here', 'below', 'were', \"wouldn't\", 'myself', \"he'd\", 'on', 'this', 'until', 'and', \"hadn't\", 'only', \"i'd\", 'being', 'off', 'd', 'no', 'of', 'ain', 'more', \"i've\", 'again', 'had', 'each'} \n",
            "\n",
            "['alice', 'beginning', 'get', 'tired', 'sitting', 'sister', 'bank', 'nothing', 'twice', 'peeped', 'book', 'sister', 'reading', 'pictures', 'conversations', 'use', 'book', 'thought', 'alice', 'without', 'pictures', 'conversation', 'considering', 'mind', 'well', 'could', 'hot', 'day', 'made', 'feel', 'sleepy', 'stupid', 'whether', 'pleasure', 'making', 'daisychain', 'would', 'worth', 'trouble', 'getting', 'picking', 'daisies', 'suddenly', 'white', 'rabbit', 'pink', 'eyes', 'ran', 'close', 'nothing', 'remarkable', 'alice', 'think', 'much', 'way', 'hear', 'rabbit', 'say', 'oh', 'dear', 'oh', 'dear', 'shall', 'late', 'thought', 'afterwards', 'occurred', 'ought', 'wondered']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_text = \" \".join(tokens)\n",
        "print(clean_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgct_bZNKJUv",
        "outputId": "f05c2ce0-f549-4795-956c-da1eb489f84b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alice beginning get tired sitting sister bank nothing twice peeped book sister reading pictures conversations use book thought alice without pictures conversation considering mind well could hot day made feel sleepy stupid whether pleasure making daisychain would worth trouble getting picking daisies suddenly white rabbit pink eyes ran close nothing remarkable alice think much way hear rabbit say oh dear oh dear shall late thought afterwards occurred ought wondered\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer\n",
        "\n",
        "words = [\"ponies\", \"studies\", \"studying\", \"maximum\", \"running\", \"runs\", \"ran\", \"sky\", \"skies\", \"news\" ]\n",
        "\n",
        "porter = PorterStemmer()\n",
        "lancaster = LancasterStemmer()\n",
        "snowball = SnowballStemmer(\"english\")\n",
        "\n",
        "print(\"Porter: \", [porter.stem(word) for word in words])\n",
        "print(\"Lancaster: \", [lancaster.stem(word) for word in words])\n",
        "print(\"Snowball: \", [snowball.stem(word) for word in words])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9fjGDJ022ew",
        "outputId": "98a63b77-7e0e-477e-d52a-c985099c2e24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Porter:  ['poni', 'studi', 'studi', 'maximum', 'run', 'run', 'ran', 'sky', 'sky', 'news']\n",
            "Lancaster:  ['pony', 'study', 'study', 'maxim', 'run', 'run', 'ran', 'sky', 'ski', 'new']\n",
            "Snowball:  ['poni', 'studi', 'studi', 'maximum', 'run', 'run', 'ran', 'sky', 'sky', 'news']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "print(tokens[:50])\n",
        "\n",
        "stems = [stemmer.stem(token) for token in tokens]\n",
        "print(stems[:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyEJ9M_X4NIL",
        "outputId": "475d089f-74af-49ad-bd3b-6d099b5bc9a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['alice', 'beginning', 'get', 'tired', 'sitting', 'sister', 'bank', 'nothing', 'twice', 'peeped', 'book', 'sister', 'reading', 'pictures', 'conversations', 'use', 'book', 'thought', 'alice', 'without', 'pictures', 'conversation', 'considering', 'mind', 'well', 'could', 'hot', 'day', 'made', 'feel', 'sleepy', 'stupid', 'whether', 'pleasure', 'making', 'daisychain', 'would', 'worth', 'trouble', 'getting', 'picking', 'daisies', 'suddenly', 'white', 'rabbit', 'pink', 'eyes', 'ran', 'close', 'nothing']\n",
            "['alic', 'begin', 'get', 'tire', 'sit', 'sister', 'bank', 'noth', 'twice', 'peep', 'book', 'sister', 'read', 'pictur', 'convers', 'use', 'book', 'thought', 'alic', 'without', 'pictur', 'convers', 'consid', 'mind', 'well', 'could', 'hot', 'day', 'made', 'feel', 'sleepi', 'stupid', 'whether', 'pleasur', 'make', 'daisychain', 'would', 'worth', 'troubl', 'get', 'pick', 'daisi', 'suddenli', 'white', 'rabbit', 'pink', 'eye', 'ran', 'close', 'noth']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "\n",
        "nltk.download(\"wordnet\")\n",
        "\n",
        "nltk.download(\"omw-1.4\")\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "words = [\"running\", \"ran\", \"better\", \"studies\"]\n",
        "\n",
        "lemmas1 = [lemmatizer.lemmatize(w, pos = \"v\") for w in words]\n",
        "print(\"lemmas1: \",lemmas1)\n",
        "\n",
        "\n",
        "lemmas2 = [lemmatizer.lemmatize(w, pos = \"a\") for w in words]\n",
        "print(\"lemmas2: \",lemmas2)\n",
        "\n",
        "lemmas3 = [lemmatizer.lemmatize(w, pos = \"n\") for w in words]\n",
        "print(\"lemmas3: \",lemmas3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zN1AfyKu5QF0",
        "outputId": "31cbfcfd-7503-4f0b-e467-fe44dee50d17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lemmas1:  ['run', 'run', 'better', 'study']\n",
            "lemmas2:  ['running', 'ran', 'good', 'studies']\n",
            "lemmas3:  ['running', 'ran', 'better', 'study']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "nltk.download(\"wordnet\")\n",
        "\n",
        "nltk.download(\"omw-1.4\")\n",
        "\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "print(\"tokens: \", tokens[: 50])\n",
        "\n",
        "lemmas = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "lemmas = [lemmatizer.lemmatize(token, pos = wordnet.VERB) for token in tokens]\n",
        "print(\"lemmas: \", lemmas[: 50])\n",
        "print(\"stems: \", stems[: 50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdiCeQu18z6G",
        "outputId": "ce99367a-ac29-4fc3-f1df-34ce4a55c038"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokens:  ['alice', 'beginning', 'get', 'tired', 'sitting', 'sister', 'bank', 'nothing', 'twice', 'peeped', 'book', 'sister', 'reading', 'pictures', 'conversations', 'use', 'book', 'thought', 'alice', 'without', 'pictures', 'conversation', 'considering', 'mind', 'well', 'could', 'hot', 'day', 'made', 'feel', 'sleepy', 'stupid', 'whether', 'pleasure', 'making', 'daisychain', 'would', 'worth', 'trouble', 'getting', 'picking', 'daisies', 'suddenly', 'white', 'rabbit', 'pink', 'eyes', 'ran', 'close', 'nothing']\n",
            "lemmas:  ['alice', 'begin', 'get', 'tire', 'sit', 'sister', 'bank', 'nothing', 'twice', 'peep', 'book', 'sister', 'read', 'picture', 'conversations', 'use', 'book', 'think', 'alice', 'without', 'picture', 'conversation', 'consider', 'mind', 'well', 'could', 'hot', 'day', 'make', 'feel', 'sleepy', 'stupid', 'whether', 'pleasure', 'make', 'daisychain', 'would', 'worth', 'trouble', 'get', 'pick', 'daisies', 'suddenly', 'white', 'rabbit', 'pink', 'eye', 'run', 'close', 'nothing']\n",
            "stems:  ['alic', 'begin', 'get', 'tire', 'sit', 'sister', 'bank', 'noth', 'twice', 'peep', 'book', 'sister', 'read', 'pictur', 'convers', 'use', 'book', 'thought', 'alic', 'without', 'pictur', 'convers', 'consid', 'mind', 'well', 'could', 'hot', 'day', 'made', 'feel', 'sleepi', 'stupid', 'whether', 'pleasur', 'make', 'daisychain', 'would', 'worth', 'troubl', 'get', 'pick', 'daisi', 'suddenli', 'white', 'rabbit', 'pink', 'eye', 'ran', 'close', 'noth']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download(\"wordnet\")\n",
        "\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "for syn in wn.synsets(\"bank\"):\n",
        "  print(syn.name(), \": \", syn.definition())\n",
        "\n",
        "for syn in wn.synsets(\"college\"):\n",
        "  print(\"college : \\n\", syn.name(), \": \", syn.definition())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMOykyc4_WMf",
        "outputId": "a8708458-1608-433f-9c07-3f3631c1449d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bank.n.01 :  sloping land (especially the slope beside a body of water)\n",
            "depository_financial_institution.n.01 :  a financial institution that accepts deposits and channels the money into lending activities\n",
            "bank.n.03 :  a long ridge or pile\n",
            "bank.n.04 :  an arrangement of similar objects in a row or in tiers\n",
            "bank.n.05 :  a supply or stock held in reserve for future use (especially in emergencies)\n",
            "bank.n.06 :  the funds held by a gambling house or the dealer in some gambling games\n",
            "bank.n.07 :  a slope in the turn of a road or track; the outside is higher than the inside in order to reduce the effects of centrifugal force\n",
            "savings_bank.n.02 :  a container (usually with a slot in the top) for keeping money at home\n",
            "bank.n.09 :  a building in which the business of banking transacted\n",
            "bank.n.10 :  a flight maneuver; aircraft tips laterally about its longitudinal axis (especially in turning)\n",
            "bank.v.01 :  tip laterally\n",
            "bank.v.02 :  enclose with a bank\n",
            "bank.v.03 :  do business with a bank or keep an account at a bank\n",
            "bank.v.04 :  act as the banker in a game or in gambling\n",
            "bank.v.05 :  be in the banking business\n",
            "deposit.v.02 :  put into a bank account\n",
            "bank.v.07 :  cover with ashes so to control the rate of burning\n",
            "trust.v.01 :  have confidence or faith in\n",
            "college : \n",
            " college.n.01 :  the body of faculty and students of a college\n",
            "college : \n",
            " college.n.02 :  an institution of higher education created to educate and grant degrees; often a part of a university\n",
            "college : \n",
            " college.n.03 :  a complex of buildings in which an institution of higher education is housed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "for s in wn.synsets(\"paper\"):\n",
        "  print(s.name(), \"-\", s.definition)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pm_jzeXaBSOK",
        "outputId": "b2dbef8d-1814-424a-a8d9-1b84437fa68c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "paper.n.01 - <bound method Synset.definition of Synset('paper.n.01')>\n",
            "composition.n.08 - <bound method Synset.definition of Synset('composition.n.08')>\n",
            "newspaper.n.01 - <bound method Synset.definition of Synset('newspaper.n.01')>\n",
            "paper.n.04 - <bound method Synset.definition of Synset('paper.n.04')>\n",
            "paper.n.05 - <bound method Synset.definition of Synset('paper.n.05')>\n",
            "newspaper.n.02 - <bound method Synset.definition of Synset('newspaper.n.02')>\n",
            "newspaper.n.03 - <bound method Synset.definition of Synset('newspaper.n.03')>\n",
            "paper.v.01 - <bound method Synset.definition of Synset('paper.v.01')>\n",
            "wallpaper.v.01 - <bound method Synset.definition of Synset('wallpaper.v.01')>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# spaCy"
      ],
      "metadata": {
        "id": "77crc_kTELSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n"
      ],
      "metadata": {
        "id": "1MsH1hxDEW_x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}