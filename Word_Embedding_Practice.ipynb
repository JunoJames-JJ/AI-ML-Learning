{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JunoJames-JJ/AI-ML-Learning/blob/main/Word_Embedding_Practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**One-hot vectors**"
      ],
      "metadata": {
        "id": "ADfaP32h8XCr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMId87808Vc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62dc4f5f-1709-41eb-b7c3-b29206d08e27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-hot for 'sat': [0 0 0 0 0 1 0]\n",
            "One-hot for 'log': [0 0 1 0 0 0 0]\n",
            "Feature order: ['cat' 'dog' 'log' 'mat' 'on' 'sat' 'the']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelBinarizer # Binarize labels in a one-vs-all fashion.\n",
        "\n",
        "# LabelBinazier Library: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html\n",
        "\n",
        "# Vocabulary\n",
        "vocab = [\"the\", \"cat\", \"sat\", \"on\", \"mat\", \"dog\", \"log\"]\n",
        "\n",
        "# Example word\n",
        "word = [\"sat\", \"log\"]\n",
        "\n",
        "\n",
        "lb = LabelBinarizer()\n",
        "lb.fit(vocab)\n",
        "\n",
        "one_hot = lb.transform(word)\n",
        "\n",
        "\n",
        "print(\"One-hot for 'sat':\", one_hot[0])\n",
        "print(\"One-hot for 'log':\", one_hot[1])\n",
        "print(\"Feature order:\", lb.classes_)  # The vocabulary is sorted alphabetically by default"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Co-occurrence matrix**"
      ],
      "metadata": {
        "id": "tI82sF1I9H3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "# defaultdict: It’s a subclass of Python’s normal dict (dictionary) with one special feature:\n",
        "# if you try to access a key that doesn’t exist, it automatically creates it with a default value instead of raising a KeyError.\n",
        "\n",
        "corpus = [\n",
        "    [\"the\", \"cat\", \"drinks\", \"milk\"],\n",
        "    [\"the\", \"dog\", \"drinks\", \"water\"]\n",
        "]\n",
        "\n",
        "window_size = 2\n",
        "vocab = sorted(set([w for doc in corpus for w in doc]))\n",
        "word2idx = {w: i for i, w in enumerate(vocab)}\n",
        "\n",
        "co_matrix = np.zeros((len(vocab), len(vocab)), dtype=int)\n",
        "\n",
        "for doc in corpus:\n",
        "    for i, word in enumerate(doc):\n",
        "        idx = word2idx[word]\n",
        "        # look at context within window\n",
        "        for j in range(max(i - window_size, 0), min(i + window_size + 1, len(doc))):\n",
        "            if i != j:\n",
        "                context = doc[j]\n",
        "                co_matrix[idx, word2idx[context]] += 1\n",
        "\n",
        "print(\"Vocabulary:\", vocab)\n",
        "print(\"Co-occurrence matrix:\\n\", co_matrix)\n"
      ],
      "metadata": {
        "id": "F5m6dGrk87lQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3d725a6-e3f8-40bd-da3e-e2f8182aecec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary: ['cat', 'dog', 'drinks', 'milk', 'the', 'water']\n",
            "Co-occurrence matrix:\n",
            " [[0 0 1 1 1 0]\n",
            " [0 0 1 0 1 1]\n",
            " [1 1 0 1 2 1]\n",
            " [1 0 1 0 0 0]\n",
            " [1 1 2 0 0 0]\n",
            " [0 1 1 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83ZfMCNjuNg-",
        "outputId": "2650316e-48a0-42d6-ec90-a9b9999b6975"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cat': 0, 'dog': 1, 'drinks': 2, 'milk': 3, 'the': 4, 'water': 5}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bag of Words**"
      ],
      "metadata": {
        "id": "AwlySNW69xc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "# CountVectorizer Library: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
        "# TfidfVectorizer Library: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
        "\n",
        "docs = [\"The cat sat on the mat\", \"The dog sat on the log\", \"The mice sat on the log\"]\n",
        "\n",
        "# --- Raw Counts ---\n",
        "count_vec = CountVectorizer()\n",
        "X_counts = count_vec.fit_transform(docs)\n",
        "print(\"Raw counts: \\n\", X_counts.toarray())\n",
        "print(\"Vocabulary mapping:\", count_vec.vocabulary_)\n",
        "print(\"Feature order:\\n\", count_vec.get_feature_names_out())\n",
        "\n",
        "# --- Binary presence ---\n",
        "binary_vec = CountVectorizer(binary=True)\n",
        "X_binary = binary_vec.fit_transform(docs)\n",
        "print(\"\\nBinary presence:\\n\", X_binary.toarray())\n",
        "\n",
        "# --- Term Frequency (TF) ---\n",
        "tf_vec = TfidfVectorizer(use_idf=False, norm=\"l1\")\n",
        "X_tf = tf_vec.fit_transform(docs)\n",
        "print(\"\\nTF:\\n\", X_tf.toarray())\n",
        "\n",
        "# --- Raw Term Frequency (TF) ---\n",
        "tf_vec = TfidfVectorizer(use_idf=False, norm=None)\n",
        "X_tf = tf_vec.fit_transform(docs)\n",
        "print(\"\\nRaw TF:\\n\", X_tf.toarray())\n",
        "\n",
        "# --- TF–IDF ---\n",
        "tfidf_vec = TfidfVectorizer(smooth_idf=True, norm=None)\n",
        "\n",
        "X_tfidf = tfidf_vec.fit_transform(docs)\n",
        "# smooth_idf=True => idf(t) = log [ (1 + n) / (1 + df(t)) ] + 1\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
        "\n",
        "print(\"\\nTF–IDF:\\n\", X_tfidf.toarray())\n",
        "\n",
        "\n",
        "# --- IDF values ---\n",
        "print(\"\\nIDF values:\")\n",
        "for term, val in zip(tfidf_vec.get_feature_names_out(), tfidf_vec.idf_):\n",
        "    print(f\"{term}: {val:.3f}\")\n"
      ],
      "metadata": {
        "id": "8XTNX3TY9wm0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c6806c0-1d0a-408b-f86c-81efbfbe6ffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw counts: \n",
            " [[1 0 0 1 0 1 1 2]\n",
            " [0 1 1 0 0 1 1 2]\n",
            " [0 0 1 0 1 1 1 2]]\n",
            "Vocabulary mapping: {'the': 7, 'cat': 0, 'sat': 6, 'on': 5, 'mat': 3, 'dog': 1, 'log': 2, 'mice': 4}\n",
            "Feature order:\n",
            " ['cat' 'dog' 'log' 'mat' 'mice' 'on' 'sat' 'the']\n",
            "\n",
            "Binary presence:\n",
            " [[1 0 0 1 0 1 1 1]\n",
            " [0 1 1 0 0 1 1 1]\n",
            " [0 0 1 0 1 1 1 1]]\n",
            "\n",
            "TF:\n",
            " [[0.16666667 0.         0.         0.16666667 0.         0.16666667\n",
            "  0.16666667 0.33333333]\n",
            " [0.         0.16666667 0.16666667 0.         0.         0.16666667\n",
            "  0.16666667 0.33333333]\n",
            " [0.         0.         0.16666667 0.         0.16666667 0.16666667\n",
            "  0.16666667 0.33333333]]\n",
            "\n",
            "Raw TF:\n",
            " [[1. 0. 0. 1. 0. 1. 1. 2.]\n",
            " [0. 1. 1. 0. 0. 1. 1. 2.]\n",
            " [0. 0. 1. 0. 1. 1. 1. 2.]]\n",
            "\n",
            "TF–IDF:\n",
            " [[1.69314718 0.         0.         1.69314718 0.         1.\n",
            "  1.         2.        ]\n",
            " [0.         1.69314718 1.28768207 0.         0.         1.\n",
            "  1.         2.        ]\n",
            " [0.         0.         1.28768207 0.         1.69314718 1.\n",
            "  1.         2.        ]]\n",
            "\n",
            "IDF values:\n",
            "cat: 1.693\n",
            "dog: 1.693\n",
            "log: 1.288\n",
            "mat: 1.693\n",
            "mice: 1.693\n",
            "on: 1.000\n",
            "sat: 1.000\n",
            "the: 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: The original textbook formula for IDF is idf(t) = log(n / (df(t) + 1)),\n",
        "but scikit-learn uses idf(t) = log(n / df(t)) + 1 (or the smoothed variant log((1+n)/(1+df(t))) + 1).\n",
        "This adjustment avoids division by zero and negative IDF values, making the weights more stable in practice.\n",
        "\n",
        "https://nlp.stanford.edu/IR-book/\n"
      ],
      "metadata": {
        "id": "rL_on1TPw5qa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Working with ngrams"
      ],
      "metadata": {
        "id": "VLsPV5Mxyh7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "docs = [\"the cat sat\"]\n",
        "\n",
        "cv1= CountVectorizer(ngram_range=(1, 1)) #unigrams\n",
        "print(\"unigrams:\", cv1.fit(docs).get_feature_names_out())\n",
        "# ['cat', 'sat', 'the']\n",
        "\n",
        "cv2= CountVectorizer(ngram_range=(1, 2)) #unigrams + bigrams\n",
        "print(\"unigrams + bigrams:\", cv2.fit(docs).get_feature_names_out())\n",
        "# ['cat', 'cat sat', 'sat', 'the', 'the cat']\n",
        "\n",
        "cv3= CountVectorizer(ngram_range=(2, 2)) #only bigrams\n",
        "print(\"only bigrams:\", cv3.fit(docs).get_feature_names_out())\n",
        "# ['cat sat', 'the cat']\n",
        "\n",
        "cv4= CountVectorizer(ngram_range=(2, 3))\n",
        "print(\"trigram: \",cv4.fit(docs).get_feature_names_out())\n",
        "# ['cat sat' 'the cat' 'the cat sat']\n",
        "\n",
        "cv5= CountVectorizer(ngram_range=(3, 3))\n",
        "print(\"trigram +: \",cv5.fit(docs).get_feature_names_out())\n",
        "#  ['the cat sat']\n",
        "\n"
      ],
      "metadata": {
        "id": "7fNtWA8NULgi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf47d780-f0d2-4d4a-9303-523087d5a45a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unigrams: ['cat' 'sat' 'the']\n",
            "unigrams + bigrams: ['cat' 'cat sat' 'sat' 'the' 'the cat']\n",
            "only bigrams: ['cat sat' 'the cat']\n",
            "trigram:  ['cat sat' 'the cat' 'the cat sat']\n",
            "trigram +:  ['the cat sat']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "docs = [\"the cat sat\", \"the dog ran\"]\n",
        "\n",
        "# --- CountVectorizer with bigrams only ---\n",
        "cv3 = CountVectorizer(ngram_range=(2, 2))\n",
        "X_counts = cv3.fit_transform(docs)\n",
        "print(\"Bigrams:\", cv3.get_feature_names_out())\n",
        "print(\"Counts:\\n\", X_counts.toarray())\n",
        "\n",
        "# --- TF-IDF with bigrams only ---\n",
        "tfidf_vec = TfidfVectorizer(ngram_range=(2, 2), smooth_idf= True, norm=\"l2\")\n",
        "X_tfidf = tfidf_vec.fit_transform(docs)\n",
        "print(\"\\nBigrams:\", tfidf_vec.get_feature_names_out())\n",
        "print(\"TF-IDF:\\n\", X_tfidf.toarray())\n"
      ],
      "metadata": {
        "id": "GahNZf6JygbC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd774f21-bb27-44e3-b2d1-287cba5b90bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bigrams: ['cat sat' 'dog ran' 'the cat' 'the dog']\n",
            "Counts:\n",
            " [[1 0 1 0]\n",
            " [0 1 0 1]]\n",
            "\n",
            "Bigrams: ['cat sat' 'dog ran' 'the cat' 'the dog']\n",
            "TF-IDF:\n",
            " [[0.70710678 0.         0.70710678 0.        ]\n",
            " [0.         0.70710678 0.         0.70710678]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **manually calculating TF * IDF**"
      ],
      "metadata": {
        "id": "OaaS4D-ayKHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer, CountVectorizer\n",
        "\n",
        "# Get TF only\n",
        "count_vec = CountVectorizer()\n",
        "X_counts = count_vec.fit_transform(docs)\n",
        "\n",
        "# Normalize TF (L1)\n",
        "tf_vec = TfidfTransformer(use_idf=False, norm=\"l1\")\n",
        "X_tf = tf_vec.fit_transform(X_counts)\n",
        "\n",
        "# Get IDF separately\n",
        "idf_only = TfidfTransformer(use_idf=True, norm=None)\n",
        "idf_only.fit(X_counts)\n",
        "idf_values = idf_only.idf_\n",
        "\n",
        "# Multiply manually: TF * IDF\n",
        "X_tf_idf = X_tf.multiply(idf_values)\n",
        "print(\"\\nTF–IDF:\\n\", X_tf_idf.toarray())\n"
      ],
      "metadata": {
        "id": "E7cAIxinbQkT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62afb297-89ab-4375-cfdc-5a5a1cd5260e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TF–IDF:\n",
            " [[0.46848837 0.         0.         0.46848837 0.33333333]\n",
            " [0.         0.46848837 0.46848837 0.         0.33333333]]\n"
          ]
        }
      ]
    }
  ]
}